{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001d216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb8d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Example input data has 10 attributes with 30 data columns - 10 mean, 10 standard error (SE), and 10 worst values\n",
    "'''\n",
    "\n",
    "df_train = pd.read_csv('data.csv', delimiter = \",\", low_memory=False)\n",
    "df_train.drop('id', axis=1, inplace=True) #remove id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e81287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the attributes: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n"
     ]
    }
   ],
   "source": [
    "attribute_num = 10 #number of attributes\n",
    "attribute_list = list(df_train.head())\n",
    "attribute_list = attribute_list[1:(1 + attribute_num)]\n",
    "print('Here are the attributes:', attribute_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c387b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_train.sample(frac = 0.3, replace = False).reset_index(drop = True) #define test set\n",
    "df_train.drop(df_test.index, inplace = True) #remove test set from training set\n",
    "df_train = df_train.transpose()\n",
    "df_test = df_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3883abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.iloc[0] #separate diagnosis data from other attribute data\n",
    "y_train = list(y_train)\n",
    "y_train = [0 if item == 'B' else item for item in y_train] #convert diagnosis from B/M to 0/1\n",
    "y_train = [1 if item == 'M' else item for item in y_train]\n",
    "\n",
    "y_test = df_test.iloc[0]\n",
    "y_test = list(y_test)\n",
    "y_test = [0 if item == 'B' else item for item in y_test]\n",
    "y_test = [1 if item == 'M' else item for item in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042451b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build tree around difference between attribute worst and means with respect to standard error (SE)\n",
    "df_difference = pd.DataFrame()\n",
    "\n",
    "for col in df_train:\n",
    "    temp = df_train[col]\n",
    "    temp_dict = {}\n",
    "    for i in range(attribute_num):\n",
    "        condition = temp[0] #diagnosis (0/1)\n",
    "        attribute = attribute_list[i] #name of attribute\n",
    "        mean = temp[i + 1] #mean of sample\n",
    "        se = temp[i + attribute_num] #se of sample\n",
    "        worst = temp[i + 2 * attribute_num] #worst of sample\n",
    "        decision_value = worst - mean + se\n",
    "        temp_dict[attribute] = decision_value\n",
    "        columns = list(temp_dict.keys())\n",
    "        series = pd.Series(temp_dict, name = condition)\n",
    "    \n",
    "    df_difference = pd.concat([df_difference, series], axis = 1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67964996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the decision points:\n",
      "                attribute     expdecpt  controldecpt\n",
      "0             radius_mean   -17.765470    -12.254644\n",
      "1            texture_mean    -0.291226     -4.206289\n",
      "2          perimeter_mean   -86.464461    -54.223203\n",
      "3               area_mean  -869.760232   -385.194063\n",
      "4         smoothness_mean  1526.133989    595.670516\n",
      "5        compactness_mean     0.010662      0.050144\n",
      "6          concavity_mean     0.217660      0.164554\n",
      "7     concave points_mean     0.389293      0.168995\n",
      "8           symmetry_mean     0.006984     -0.087159\n",
      "9  fractal_dimension_mean     0.261947      0.229646\n"
     ]
    }
   ],
   "source": [
    "templist = []\n",
    "\n",
    "for i, iter in df_difference.iterrows():\n",
    "    controllist = iter['B']\n",
    "    experimentallist = iter['M']\n",
    "    controlmean = controllist.mean()\n",
    "    controlSE = controllist.sem()   \n",
    "    experimentalmean = experimentallist.mean()\n",
    "    experimentalSE = experimentallist.sem()    \n",
    "    if controlmean > experimentalmean:\n",
    "        controldecisionpt = controlmean - controlSE\n",
    "        experimentaldecisionpt = experimentalmean + experimentalSE\n",
    "    if controlmean < experimentalmean:\n",
    "        controldecisionpt = controlmean + controlSE\n",
    "        experimentaldecisionpt = experimentalmean - experimentalSE  \n",
    "    templist.append([i, experimentaldecisionpt, controldecisionpt])\n",
    "    \n",
    "df_decision = pd.DataFrame(templist, columns = ['Attribute', 'Malignant Decision Point', 'Benign Decision Point'])\n",
    "print('Here are the decision points:')\n",
    "print(df_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a97281ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply decision points to training data\n",
    "attdeclist = []\n",
    "\n",
    "for col in df_train:\n",
    "    temp = df_train[col]\n",
    "    attdectotal = 0\n",
    "    \n",
    "    for i in range(attribute_num):\n",
    "        condition = temp[0]\n",
    "        attribute = attribute_list[i]\n",
    "        mean = temp[i + 1]\n",
    "        se = temp[i + attribute_num]\n",
    "        worst = temp[i + 2 * attribute_num]\n",
    "        decision_value = worst - mean + se\n",
    "        tempdecpt = df_decision.iloc[i]\n",
    "     \n",
    "        if tempdecpt[1] > tempdecpt[2]:\n",
    "            if decision_value > tempdecpt[1]:\n",
    "                attdec = 1\n",
    "            elif decision_value < tempdecpt[2]:\n",
    "                attdec = 0\n",
    "            else:\n",
    "                attdec = 0.5\n",
    "        if tempdecpt[1] < tempdecpt[2]:\n",
    "            if decision_value < tempdecpt[1]:\n",
    "                attdec = 1\n",
    "            elif decision_value > tempdecpt[2]:\n",
    "                attdec = 0\n",
    "            else:\n",
    "                attdec = 0.5\n",
    "        attdectotal = attdectotal + attdec\n",
    "    if attdectotal > 5: #if running sum metric is >5 then guess that sample is malignant\n",
    "        guess = 1\n",
    "    else:\n",
    "        guess = 0\n",
    "    attdeclist.append(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1f4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree is 88.7 % accurate on training data.\n"
     ]
    }
   ],
   "source": [
    "#compare training set results with actual values\n",
    "correct = 0\n",
    "\n",
    "for index in range(len(y_train)):\n",
    "    trainguess = attdeclist[index]\n",
    "    trainreal = y_train[index]\n",
    "    if trainguess == trainreal:\n",
    "        correct = correct + 1\n",
    "\n",
    "accuracy = (correct / (len(y_train)))*100\n",
    "print('The decision tree is', round(accuracy,1), '% accurate on training data.')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5157e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply decision points to test data\n",
    "attdeclist = []\n",
    "\n",
    "for col in df_test:\n",
    "    temp = df_test[col]\n",
    "    attdectotal = 0\n",
    "    \n",
    "    for i in range(attribute_num):\n",
    "        condition = temp[0]\n",
    "        attribute = attribute_list[i]\n",
    "        mean = temp[i + 1]\n",
    "        se = temp[i + attribute_num]\n",
    "        worst = temp[i + 2 * attribute_num]\n",
    "        decision_value = worst - mean + se\n",
    "        tempdecpt = df_decision.iloc[i]\n",
    "        \n",
    "        if tempdecpt[1] > tempdecpt[2]:\n",
    "            if decision_value > tempdecpt[1]:\n",
    "                attdec = 1\n",
    "            elif decision_value < tempdecpt[2]:\n",
    "                attdec = 0\n",
    "            else:\n",
    "                attdec = 0.5\n",
    "        if tempdecpt[1] < tempdecpt[2]:\n",
    "            if decision_value < tempdecpt[1]:\n",
    "                attdec = 1\n",
    "            elif decision_value > tempdecpt[2]:\n",
    "                attdec = 0\n",
    "            else:\n",
    "                attdec = 0.5\n",
    "        attdectotal = attdectotal + attdec\n",
    "    if attdectotal > 5:\n",
    "        guess = 1\n",
    "    else:\n",
    "        guess = 0\n",
    "    attdeclist.append(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a899868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree is 100.0 % accurate on test data.\n"
     ]
    }
   ],
   "source": [
    "#compare test set results with actual values\n",
    "correct = 0\n",
    "\n",
    "for index in range(len(y_test)):\n",
    "    testguess = attdeclist[index]\n",
    "    testreal = y_test[index]\n",
    "    if trainguess == trainreal:\n",
    "        correct = correct + 1\n",
    "\n",
    "accuracy = (correct / (len(y_test)))*100\n",
    "print('The decision tree is', round(accuracy,1), '% accurate on test data.')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
